# 操作系统
## 一.内核（OS Kernel）特征
 * **并发**（不同于并行，并行必须为多核）：计算机系统中同时存在多个运行的程序，需要OS管理和调度
 * **共享**：“同时”访问，互斥共享
 * **虚拟**：利用多道程序设计技术，让每个用户（应用程序）都觉得有一个计算机专门为他服务
 * **异步**：程序的执行不是一贯到底，而是走走停停，向前推进的素的不可预知，但只要运行环境相同，OS需要保证程序<br/>运行的结果也要相同</br>
## 二.操作系统的启动
 * **DISK**：存放OS，bootloader也在DISK存储着
 * **BIOS**：基本I/O处理系统，开机检测各种各样的 I/O外设，BIOS系统程序本身就在内存里放着，不在DISK内
 * 所谓CPU控制权的交接，可以理解为CPU执行哪段代码，刚刚启动时，CPU执行BIOS程序代码，BIOS程序代码也可以控制CUP跳到内存的其它地址空间执行相应的程序，当    BIOS程序执行完毕开始执行加载进来的bootloader代码时，可以说BIOS将CPU的控制权交给了bootloader
 * 操作系统与设备和程序交互（操作系统 interface）：系统调用、异常、中断，面向外设是通过中断和IO来处理的，面向应用程序是通过系统调用和异常来处理
 * 用户态、内核态
## 三.计算机体系结构及内存分层
 * **逻辑地址**：是指由程序产生的与段相关的偏移地址部分，逻辑地址是连续的。
 * **逻辑地址空间**：逻辑地址空间是逻辑地址的范围，一个程序的逻辑地址空间大于等于其物理地址空间，那么有一个疑问，逻辑地址空间和物理地址空间都是在内存（RAM）上存储的，并且逻辑地址空间不小于物理地址空间，那么为何不将物理地址空间存储的内容直接放进逻辑地址空间，反而要多此一举的搞一个逻辑空间呢？答案肯定不是我们目前所设想的那样。我们注意到逻辑地址是连续的，按以前所设想的在内存上建立一个逻辑地址空间的话，那么其存储的内容会有大量的重复信息比如（页号，偏移量）：（0,0）（0,1）（0,2）（0,3）...,**既然逻辑地址是连续的那么我们只需知道首逻辑地址就行了，其它地址利用程序计数器依次加一就好了**，这样我们不需要建立整个逻辑地址存储空间，只需记录首逻辑地址即其它少量控制信息就行了。那么就剩下页表（逻辑地址页和物理地址帧的映射表）比较消耗内存了，如果页表所消耗内存比分配的物理内存还大，那么也就没必要做逻辑地址和物理地址的映射了，这种情况一般不会发生。
 * **虚拟内存**：内存指的是电脑的RAM，虚拟内存是将磁盘硬盘的内存虚拟化为内存，具体是将RAM里面暂时不用的数据程序存储到硬盘里，从而省出了内存的部分空间，可以看成虚拟化硬盘的一部分存储空间为内存
 * **地址空间**：物理地址和逻辑地址，逻辑地址是连续的，CPU依据逻辑地址去寻找相应的物理地址
 * **连续内存分配**：内存碎片问题、分区的动态分配包括第一适配、最佳适配、最差适配，压缩式碎片整理、交换式碎片整理
## 四.非连续内存分配
 * **分段**：段号+段内偏移量，段的大小不同，好处是可以实现隔离和共享  
 * **分页**：页号+偏移量，每页的大小相同。逻辑地址的页对应物理地址的帧，一般来说页的数目大于帧的数目，因为共享机制的存在
 * **页表**：页表就是一个大的数组
 * **TLB**：缓存近期访问的页帧转换表项，加快访问速度
 * **多级页表**：以时间换空间，分级次数越多，访问的次数也就越多，那些对应关系不在内存里的页表（flag里resident标志位为0的页表，也就是不合法页表）就占用内&emsp;　存的空间了
 * **反向页表**：以帧号为index，以页号为存储内容，这样的话页表的大小只与物理地址空间大小有关，而与逻辑地址空间大小无关，页表是小了，但查找费时间
 * **相应的方案有**：(1)基于页寄存器的方案，但无法索引，因为我们要的是根据页号获得帧号。(2)基于关联内存（类似HashMap）的方案，key放置页号，value放置帧号，缺点是造价高，太大时也无法放进CPU内存。(3)基于哈希（hash）查找的方案。
 ## 五.虚拟内存技术
 * 程序规模的增长远大于存储器容量的增长速度 ，让更多的程序运行在有限的内存内  
 <div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/memorizer.PNG" width=50% /></div>   
 
 * **覆盖技术**  
   * **目标**：在较小的可用内存中运行较大的程序，常用于多道程序系统，与区分存储管理配合使用
   * **原理**：把程序按照其自身逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行
   * **缺点**：(1)程序员要划分功能区，增加了编程的复杂度  
   &emsp;&emsp;&emsp;(2)覆盖模块从外出装入内存，实际上是以时间换空间
 * **交换技术**  
   * **目标**：多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源  
   * **方法**：可将暂时不能运行的程序送到外存，从而获得空闲内存空间
   * **缺点**：增加了处理器的开销
 * **覆盖与交换的比较**  
   * 覆盖只能发生在那些相互之间没有调用关系的程序模块之间，因此程序员必须给出程序内的各个模块之间逻辑覆盖结构。
   * 交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。换言之，交换发送在内存中程序与管理程序或操作系统之间，而覆盖则发生在运行程序的内部
 * **虚存技术**（Physical Memory + Disk = Virtual Memory） 
   * **目标**：(1)像覆盖技术那样，不是把程序的所有内容都放在内存中，但要做得更好，由操作系统自动来完成，无需程序员的干涉  
   &emsp;&emsp;&emsp;(2)像交换技术那样，能够实现进程在内存与外存之间的交换，但要做的更好，只对进程的部分内容在内存和外存之间进行交换
   * **程序的局部性原理**：指程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域，表现为时间局部性和空间局部性
   * **基本概念**  
     * 在装入程序时，不必将其全部装入到内存，而只需要将当前需要执行的部分页面或段装入到内存，就可以让程序开始执行
     * 在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或却段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序
     * 另一方面，操作系统将内存中暂时不使用的页面或段调出保存在外存上，从而腾出更多空间存放将要装入的程序以及将要调入的页面或段
## 六.虚拟内存技术（二）
* **最优页面置换算法**  
  * **功能**：当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个物理页面被置换
  * **目标**：尽可能地减少页面的换进换出次数（即缺页中断的次数）。具体来说，把未来不会再使用的或短期内较少使用的页面换出，通常只能在局部性原理指导下依据过去的统计数来进行预测；
  * **基本思路**：当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需要等待多长时间，丛总选择等待时间最长的那个，作为被置换的页面。但这只是一种理想情况，在实际系统中是无法实现的，因为操作系统无从知道每一个页面要等待多长时间以后才会再次被访问。可用作其他算法的性能评价的依据（在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法）。
  * **页面锁定（frame locking）**：用于描述必须常驻内存的操作系统的关键部分或时间键（time-critical）的应用进程。实现的方法是：在页表中添加锁定标志位（lock bit）
* **先进先出算法（FIFO）**
  * **基本思路**：选择在内存中驻留时间最长的页面并淘汰之。具体来说，系统维护着一个链表，记录了所有位于内存当中的逻辑页面。从链表的排列顺序来看，链首页面的驻留时间最长，链尾页面的驻留时间最短。当发生一个缺页中断时，吧链首页面淘汰出局，并把新的页面添加到链表的末尾。
  * **缺点**：性能较差，调出的页面有可能是经常要访问的页面，并且有Belady现象。FIFO算法很少单独使用。
  * **Belady现象**：在采用FIFO算法时，有时会出现分配的物理页面数增加，缺页率反而提高的异常现象。
  * **Belady现象的原因**：FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标是不一致的（即替换较少使用的页面），因为，被它置换出去的页面并不一定是进程不会访问的。
* **最近最近未使用算法（Least Recently Used LRU）**
  * **基本思路**：当一个缺页中断发生时，选择最久未使用的那个页面，并淘汰之。它是对最优页面置换算法的一个近似，其依据是程序的局部性原理，即在最近一小段时间（最近几条指令）内，如果某些页面被频繁地访问，纳秒在将来的一小段时间内，它们还可能会再一次被频繁地访问。反过来说，如果在过去某些页面长时间未被访问，那么在将来它们还可能会长时间地得不到访问。
  * **缺点**：LRU算法需要记录各个页面使用时间的先后顺序，开销比较大
  * **实现方法**  
    * 系统维护一个页面链表，最近刚刚使用过的页面作为首结点，最久未使用的页面作为尾结点。每一次党文内存时，找到相应的页面，把它从链表中摘下来，在移动到链表之首。每次缺页中断发生时，淘汰链表末尾的页面。
    * 设置一个活动页面栈（不是通常意义上的栈，通常意义的栈只能在栈顶操作，不能直接操作栈的中间部分和栈底），当访问某页时，将此页号压入栈顶，然后，考察栈内是否有与此页面相同的页号，若有则抽出。当需要淘汰一个页面时，总是选择栈底的页面，它就是最久未使用的。
* **时钟页面置换算法**
  * Clock页面置换算法，LRU的近似，对FIFO的一种改进。
  * **基本思路**
    * 需要用到页表项当中的访问位，当一个页面被装入到内存时，把该位初始化为0,。然后如果这个页面被访问（读/写），则把该位置为1；
    * 把各个页面组织成环形链表（类似钟表明），把指针指向最老的页面（最先进来）；
    * 当发生一个缺页中断时，考察指针所指向的最老页面，若它的访问位为0，立即淘汰；若访问位为1，则把该位置为0，然后指针往下移动一格。如此下去，直到找到被淘汰的页面，然后把指针移动到它的下一格
* **二次机会法**
  * Clock页面置换算法，LRU的近似，对FIFO的一种改进。
  * **基本思路**
    * 这里有一个巨大的代价来替换“脏”页（dirty page，也就是对该页做了写操作）。
    * 修改Clock算法，使它允许脏页总是在一次时钟头扫描中保留下来
    * 同时使用脏位和使用位来指导置换，被执行写操作次数越多的页，越不容易被替换出去
* **最不常用算法（Least Frequently Used,LFU）**  
  * **基本思路**：当一个缺页中断发生时，选择访问次数最少的那个页面，并淘汰之
  * **实现方法**：对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器加 1.在发生缺页中断时，淘汰计数值最小的那个页面
  * **LRU和LFU的区别**：LRU考察的是多久未访问，时间越短越好；而LFU考察的是访问的次数或频度，访问次数越多越好。
* **局部页替换算法的问题** 
  * 前面介绍的各种页面置换算法，都是基于一个前提，即**程序的局部性原理**，如果局部性原理不成立，那么各种页面置换算法就没有什么分别，局部性原理存在的证明、定量分析要依靠工作集模型。
* **工作集模型**  

&emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%B7%A5%E4%BD%9C%E9%9B%86.PNG" width = 40.2% />&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%B7%A5%E4%BD%9C%E9%9B%86%E4%BE%8B%E5%AD%90.PNG" width = 41% />  
&emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%B8%B8%E9%A9%BB%E9%9B%86.PNG" width = 40.2% />&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%B7%A5%E4%BD%9C%E9%9B%86%E5%A4%A7%E5%B0%8F%E5%8F%98%E5%8C%96.PNG" width = 41% />  
* **两个全局置换算法**  
  * **工作集页面置换算法**：追踪之前τ个的引用，在之前τ个内存访问的页引用是工作集，τ被称为窗口大小。
  * **缺页率页面置换算法**
    * **可变分配策略**：常驻集大小可变。例如：每个进程在刚刚开始运行的时候，先根据程序大小给它分配一定数目的物理页面，然后在进程运行过程中，再动态地调整常驻集的大小。
    * 可采用全局页面置换的方式，当发生一个缺页中断时，被置换的页面可以是在其它进程当中，各个并发进程竞争地使用物理页面。
    * **优缺点**：性能较好，但增加了系统开销。
    * **具体实现**：可以使用缺页率算法（PFF，page fault frequency）来动态调整常驻集的大小。
    * **缺页率**：缺页次数/内存访问次数。
    * **影响缺页率的因素**
      * 页面置换算法
      * 分配给进程的物理页数目
      * 页面本身的大小
      * 程序的编写方法
    * **一个交替的工作集计算明确的试图最小化页缺失**
      * 当缺页率高的时候--增加工作集
      * 当缺页率低的时候--减少工作集
      * **算法**：保持追踪缺失发生概率
        * 当发生缺失时，从上次页缺失起计算这个时间记录这个时间，t_last是上次的页缺失的时间。
        * 如果发生页缺失之间的时间是“大”的，之后减少工作集，如果t_current-t_last>T,之后从内存中移除所有在[t_last，t_current]时间内没有被引用的页。
        * 如果发生页缺失之间的时间是“小”的，之后增加工作集，如果t_current-t_last<=T,之后增加缺失页到工作集中。
        <div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%BA%A4%E6%9B%BF%E5%B7%A5%E4%BD%9C%E9%9B%86%E8%AE%A1%E7%AE%97.PNG" width=50% /></div> 

## 七.进程
* **进程定义**：一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程。
* **进程组成**：包含了正在运行的一个程序的所有状态信息。
  * 程序的代码
  * 程序处理的数据
  * 程序计数器中的值，指示下一条将要运行的指令；
  * 一组通用的寄存器的当前值，堆、栈；
  * 一组系统资源（如打开的文件）；
* **进程与程序的关系**
  * 程序是产生进程的基础
  * 程序的每次运行构成不同的进程
  * 进程是程序功能的体现
  * 通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序
* **进程与程序的区别**
  * 进程是动态的，程序是静态的;程序是由序代码的集合；进程是程序的执行，进行有核心态/用户态
  * 进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可长久保存
  * 进程与程序的组成不同：进程的组成包括程序、数据和进程控制块（即进程状态信息）
* **进程的类比**
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BF%9B%E7%A8%8B%E7%B1%BB%E6%AF%94.PNG" width=50% /></div>  

  * 这个科学家**一天的安排计划表**可以看做是**操作系统**，科学家（CPU）按照安排计划表进行一天的各种工作进程，或者按**时间点**或者按**进程处理的状态**，科学家时不时的查看安排计划表来直到当前以及接下来的工作。处理儿子被蜜蜂蛰可以看成外部中断进程。
* **进程的特点**
  * 动态性：可动态地创建、结束进程；
  * 并发性：进程可以被独立调度并占用处理机运行；**并发并行**
  * 独立性：不同进程的工作不相互影响；**分页机制可以保证，不同的进程分配不同的页表**
  * 制约性：因访问共享数据/资源或进程同步而产生制约。
  * 描述进程的数据结构：进程控制块（Process Control Block,PCB）,操作系统为每个进程都维护了一个PCB，用来保持与该进程有关的各种状态信息
* **进程控制块**：操作系统管理控制进程运行所用的信息集合。操作系统用PCB来描述进程的基本情况以及运行变化的过程，PCB是进程存在的唯一标志。 
  * **进程的创建**：为该进程生成一个PCB；
  * **进程的终止**：回收它的PCB；
  * **进程的组织管理**：通过对PCB的组织管理来实现；
* **PCB三大类信息**
  * **进程标识信息**：如本进程的标识，本进程的产生者标识（父进程标识）；用户标识。
  * **处理机状态信息保存区**：保存进程的运行现场信息；
    * **用户可见寄存器**：用户程序可以使用的数据，地址等寄存器。
    * **控制和状态寄存器**：如程序计数器（PC），程序状态字(PSW)。
    * **栈指针**：过程调用/系统调用/中断处理和返回时需要用到它。
  * **进程控制信息**
    * **调度和状态信息**：用于操作系统调度进程并占用处理机使用。
    * **进程间通信信息**：为支持进程间的与通信相关的各种标识、信号、信件等，这些信息存在接收方的进程控制块中。
    * **存储管理信息**：包含有指向本进程映像存储空间的数据结构。
    * **进程所用资源**：说明由进程打开、使用的系统资源，如打开的文件等。
    * **有关数据结构连接信息**：进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB。
* **PCB三大类信息**
  * **PCB的组织方式**
    * **链表**：同一状态的进程其PCB成一链表，多个状态对应多个不同的链表。各状态的进程形成不同的链表：就绪链表，阻塞链表。
    * **索引表**：同一状态的进程归入一个index表（由index指向PCB），多个状态对应多个不同的index表。各状态的进程形成不同的索引表：就绪索引表，阻塞索引表。
* **进程的声明周期原理**
  * **进程创建**：引起进程创建的3个主要事件
    * **系统初始化时**
    * **用户请求创建一个新进程**
    * **正在运行的进程执行了创建进程的系统调用**
  * **进程运行**
    * 内核选择一个就绪的进程，让它占用处理机并执行。
  * **进程等待**：在以下情况下，进程等待（阻塞）
    * 请求并等待系统服务，无法马上完成
    * 启动某种操作，无法马上完成
    * 需要的数据没有到达
    * **进程只能自己阻塞自己，因为只有进程自身才能知道何时需要等待某种事件的发生**
  * **进程唤醒**：唤醒进程的原因
    * 被阻塞进程需要的资源可被满足
    * 被阻塞进程等待的事件到达
    * 将该进程的PCB插入到就绪队列
    * **进程只能被别的进程或操作系统唤醒**
  * **进程结束**：在以下四种情形下，进程结束
    * 正常退出（自愿的）
    * 错误退出（自愿的）
    * 志明错误（强制性的）
    * 被其他进程所杀（强制性的）
* **进程状态变化模型**
  * **进程的三种基本状态**：进程在生命结束前**处于且仅处于**三种基本状态之一，不同系统设置的进程状态数目不同。
    * **运行状态（Running）**：当一个进程正在处理机上运行时。
    * **就绪状态（Ready）**：一个进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行。
    * **等待状态（又称阻塞状态Blocked）**：一个进程正在等待某一事件而暂停运行时。如等待某资源，等待输入/输出完成。

<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BF%90%E8%A1%8C%E5%9B%BE.PNG" width = 50% /><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E5%9B%BE.PNG" width = 46.2% />

* **进程挂起**：进程在挂起状态时，意味着进程没有占用内存空间。出在挂起状态的进程映像在磁盘上。
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BF%9B%E7%A8%8B%E6%8C%82%E8%B5%B7.PNG" width=70% /></div>  

* **挂起状态**
  * **阻塞挂起状态**：进程在外存并等待某件事的出现；
  * **就绪挂起状态**：进程在外存，但只要进入内存，即可运行；

* **与挂起相关的状态转换**
  * **挂起（Suspend）**：把一个进程从内存转换到外存；可能有以下几种情况。
    * **阻塞到阻塞挂起**：没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种转换，以提交新进程或运行就绪进程； 
    * **就绪到就绪挂起**：当有高优先级阻塞（系统认为会很快就绪的）进程和低优先就绪进程时，系统会选择挂起低优先级就绪进程；
    * **运行到就绪挂起**：对抢先式分时系统，当有高优先级阻塞挂起进程因时间出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态；
  * **在外存时的状态转换**
    * **阻塞挂起到就绪挂起**：当有阻塞挂起进程因相关时间出现时，系统会把阻塞挂起进程转换为就绪挂起进程。
  * **解挂/激活（Active）**：把一个进程从外存转换到内存；
    * **就绪挂起到就绪**：没有就绪进程或挂起就绪进程优先级高于就绪进程时，会进行这种转换；
    * **阻塞挂起到阻塞**：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起（系统认为会很快出现所等待的事件）进程转换为阻塞进程。
* **状态队列**
  * 由操作系统来维护一组队列，用来表示系统当中所有进程的当前状态；
  * 不同的状态分别用不同的队列来表示（就绪队列、各种类型的阻塞队列）；
  * 每个进程的PCB都根据它的状态加入到相应的队列当中，当一个进程的状态发生变化时，它的PCB从一个状态队列中脱离出来，加入到另外一个队列。
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%8A%B6%E6%80%81%E9%98%9F%E5%88%97.PNG" width=70% /></div>  

* **线程（Thread）管理**
  * 自从60年代提出进程概念以来，在操作系统中一直都是以进程作为独立运行的基本单位，直到80年代中期，人们又提出了更小的能独立运行的基本单位——线程
* **线程实体**
  * 线程实体之间可以并发地执行；
  * 线程实体之间共享相同的地址空间；
* **线程**：**进程当中的一条执行流程，一个进程可以有多个线程**，从两个方面来**重新理解进程**
  * **从资源组合的角度**：进程把一组相关的资源组合起来，构成了一个资源平台（环境），包括地址空间（代码段、数据段）、打开的文件等各种资源；
  * **从运行的角度**：代码在这个资源平台上的一条执行流程（线程）。
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%BA%BF%E7%A8%8B.PNG" width=65% /></div> 

  * **线程=进程-共享资源**：不同进程之间不能共享资源。
  
<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%BA%BF%E7%A8%8B%E6%89%80%E9%9C%80%E8%B5%84%E6%BA%90.PNG" width=50% /><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%8D%E5%90%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%B9%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%94%AF%E6%8C%81.PNG" width=42% />
  
  * **线程的优点**
    * 一个进程中可以同时存在多个线程；
    * 各个线程之间可以并发地执行；
    * 各个线程之间可以共享地址空间和文件等资源
  * **线程的缺点**
    * 一个线程崩溃，会导致其所属进程的所有线程崩溃。
* **线程与进程的比较**
  * 进程是资源分配单位，线程是CPU调度单位；
  * 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
  * 线程同样具有就绪、阻塞和执行三种基本状态，同样具有状态之间的转换关系；
  * 线程能减少并发执行的时间和空间开销；
    * 线程的创建时间比进程短；
    * 线程的终止时间比进程短；
    * 同一进程内的线程切换时间比进程短；
    * 由于同一进程的各线程间共享内存和文件资源，可直接进行不通过内核的通信。
* **线程的实现**：主要有三种线程的实现方式
  * **用户线程**：在用户空间实现,操作系统看不到，由应用态的库来管理；POSIX Pthreads,Mach C-threads,Solaris threads
    * 在用户空间实现的线程机制，他不依赖于操作系统的内核，由一组用户级的线程库函数来完成线程的管理，包括进程的创建、终止、同步和调度等.
    * 由于用户线程的维护由相应进程来完成（通过线程库函数），不需要操作系统内核了解用户线程的存在，**可用于不支持线程技术的多进程操作系统**；
    * 每个进程都需要它自己私有的线程控制块（TCB）列表，用来跟踪记录它的各个线程的状态信息（PC、栈指针、寄存器），TCB由线程库函数来维护；
    * 用户线程的切换也是由线程库函数来完成，无需用户态/核心态切换，所以速度特别快；
    * 允许每个进程拥有自定义的线程调度算法。
  * **内核线程**：在内核中实现，操作系统来管理，是指在操作系统的内核当中实现的一种线程机制，由操作系统的内核来完成线程的创建、终止和管理；Windows，Solaris,Linux。
    * 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息（PCB和TCB）
    * 线程的创建、终止和切换都是通过系统调用/内核函数的方式来进行，由内核来完成，因此系统开销较大。
    * 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
    * 时间片分配给线程，多线程的进程获得更多CPU时间；
    * Windows NT 和 Windoes 2000/XP 支持内核线程。
  * **轻量级进程**：在内核中实现，支持用户线程，操作系统来管理，它是内核支持的用户线程。一个进程可有一个或多个轻量级进程，每个轻量级进程由一个单独的内核线程来支持；Solaris (LightWeight Process )
* **用户线程与内核线程的对应关系**
  * &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;**多对一**
    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;&nbsp;&nbsp;**一对一**
    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;**多对多**     
&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%A4%9A%E5%AF%B9%E4%B8%80.PNG" width=25% />&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%80%E5%AF%B9%E4%B8%80.PNG" width=30% />&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%A4%9A%E5%AF%B9%E5%A4%9A.PNG" width=25% />

* **用户线程缺点**
    * 阻塞性的系统调用如何实现？如果一个线程发起系统调用而阻塞，则整个进程在等待。**因为操作系统无法识别用户线程，只能识别整个进程**，一旦一个用户线程发起系统调用而阻塞，操作系统会将整个进程至于等待，该进程的其它线程自然也处于等待状态。
    * 当一个线程开始运行后，除非它主动地交出CPU的使用权，否则它所在的进程当中的其他线程将无法运行；
    * 由于时间片分配给进程，故与其它进程比，在多线程执行时，每个线程得到的时间片较少，执行会较慢。
* **上下文切换**：停止当前运行进程（从运行状态改变成其他状态）并且调度其他进程（转变成运行状态）。
  * 必须在切换之前存储许多部分的进程上下文
  * 必须能够在之后恢复他们，所以进程**不能显示它曾经被暂停过**。
  * 必须快速（上下文转换是非常频繁的）  
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2.PNG" width=50% /></div>  
  
* **上下文切换需要存储的内容**
  * 寄存器（PC,SP,...）,CPU状态，...
  * 一些时候可能会费时，所以我们应该尽可能避免
* 操作系统为活跃进程准备了进程控制块（PCB）
* 操作系统将进程控制块（PCB）放置在一个合适的队列里
  * 就绪队列
  * 等待I/O队列（每个设备的队列）
  * 僵尸队列
* **进程控制——加载和执行进程**  
  * 一个进程，包括代码、数据和分配给进程的资源。**fork（）**函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。**相当于克隆了一个自己**。
  * **Exec()** 允许一个进程“加载”一个不同的程序并且在main开始执行（事实上—start)
  * 它允许一个进程指定参数的数量（argc）和它字符串参数数组（argv）
  * 如果调用成功
    * 它是相同的进程...
    * 但是它运行了一个不同的程序！！
  * 代码，stack（栈）& heap（堆）重写
* **进程控制——等待和终止进程**  
  * **wait（）系统调用是被父进程用来等待子进程的结束**
    * 一个子进程向父进程返回一个值，所以父进程必须接受这个值并处理
    * wait（）系统调用担任这个要求
      * 它使父进程去睡眠来等待子进程的结果
      * 当一个子进程调用exit（）的时候，操作系统解锁父进程，并且将通过exit（）传递得到的返回值作为wait调用的一个结果（连同子进程的pid一起）如果这里没有子进程存活，wait（）立刻返回
      * 当然，如果这里有为父进程的僵尸等待，wait（）立刻返回其中一个值（并且接触僵尸状态）
  * 进程结束执行之后，它调用exit（）
  * 这个系统调用：
    * 将这程序的“结果”作为一个参数
    * 关闭所有打开的文件，连接等待
    * 释放内存
    * 释放大部分支持进程的操作系统结构
    * **检查是否父进程是存活着的**：
      * **如果是的话，它保留结果的值知道父进程需要它；在这种情况下，进程没有真正死亡，但是它进入了僵尸(zombie/defunct)状态**
      * 如果没有，它释放所有的数据结构，这个进程死亡
    * 清理所有等待的僵尸进程
  * 进程终止是最终的垃圾收集（资源回收）
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/zombie.PNG" width=50% /></div>  

* **进程与线程总结**：**进程和线程都是一个时间段的描述，是CPU工作时间段的描述。**
  * **一个最最基础的事实**：CPU太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在CPU看来就是轮流着来。
  * **一个必须知道的事实**：执行一段程序代码，实现一个功能的过程介绍 ，当得到CPU的时候，相关的资源必须也已经就位，就是显卡啊，GPS啊什么的必须就位，然后CPU开始执行。这里除了CPU以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的CPU执行时间用完了，那它就要被切换出去，等待下一次CPU的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被CPU临幸的运行环境，必须保存。
  * **串联起来的事实**：前面讲过在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：**先加载程序A的上下文，然后开始执行A，保存程序A的上下文，调入下一个要执行的程序B的程序上下文，然后开始执行B,保存程序B的上下文。。。。**
  * **重要的东西出现了**：进程和线程就是这样的背景出来的，**两个名词不过是对应的CPU时间段的描述，名词就是这样的功能**。
  * **进程就是包换上下文切换的程序执行时间总和 = CPU加载上下文+CPU执行+CPU保存上下文**
  * **线程是什么**:进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序A，实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成：程序A得到CPU =》CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。**这里a，b，c的执行是共享了A的上下文，CPU在执行的时候没有进行上下文切换的。这里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段**。
* **总结**:**进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同**。
## 八.调度
* **背景**
  * **上下文切换**
    * 切换CPU的当前任务，从一个进程/线程到另一个
    * 保存当前进程/线程在PCB、TCB中的执行上下文（CPU状态）
    * 读取下一个进程/线程的上下文
  * **CPU调度**
    * 从就绪队列中挑选一个进程/线程作为CPU将要运行的下一个进程/线程
    * 调度程序：挑选进程/线程的内核函数（通过一些调度策略）
    * 什么时候进行调度？
  * **内核运行调度程序的条件（满足一条即可）**
    * 一个进程从运行状态切换到等待状态
    * 一个进程被终结了
  * **不可抢占**
    * 调度程序必须等待事件结束
  * **可以抢占**
    * 调度程序在中断被响应后执行
    * 当前的进程从运行切换到就绪，或者一个进程从等待切换到就绪
    * 当前运行的进程可以被换出
* **调度原则**
  * **执行模型**：程序在CPU突发和I/O中交替
    * 每个调度决定都是关于在下一个CPU突发时将哪个工作交给CPU
    * 在时间分片机制下，线程可能在结束当前CPU突发前被迫放弃CPU 
  * **评价指标**
    * **CPU使用率**：CPU处于忙状态所占用时间的百分比
    * **吞吐量**：在单位时间内完成的进程数量
    * **周转时间**：一个进程从初始化到结束，包括所有等待时间所花费的时间
    * **等待时间**：进程在就绪队列中的总时间
    * **响应时间**：从一个请求被提交到产生第一次相应所花费的总时间
  * **调度算法所期待的效果**
    * **减少响应时间**：及时处理用户的输出并且尽快将输出提供给用户
    * **减少平均响应时间的波动**：在交互系统中，可预测性比高差异低平均更重要
    * **增加吞吐量**
      * 减少开销（操作系统开销，上下文切换）
      * 系统资源的高效利用（CPU，I/O设备）
    * **减少等待时间**：减少每个进程的等待时间
    
    * 低延迟调度增加了交互式表现
    * 但是操作系统需要保证吞吐量不受影响
    * 吞吐量是操作系统的计算带宽
    * 响应时间是操作系统的计算延迟
    
    * **公平的定义**
      * 保证每个进程占用相同的CPU时间
      * 保证每个进程都等待相同的时间
      * **公平通常会增加平均响应时间**
* **调度算法 1**
  * **FCFS（先来先服务）**:First Come, First Served
  * **SPN（SJF） SRT（短进程优先（短作业优先）短剩余时间优先）** ：Shortest Process Next(Shortest Job First), Shortest Remaining Time
  * **HRRN（最高响应比优先）**：Highest Response Ratio Next
  * **Round Robin（轮循）**：使用时间切片和抢占来轮流执行任务
  * **Multilevel Feedback Queues（多级反馈队列）**：优先级队列中的轮循
  * **Fair Share Scheduling（公平共享调度）**  
  
  * **FCFS（先来先服务）调度算法**  
  &emsp;&emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/FIFO%E8%B0%83%E5%BA%A6.PNG" width=50% />
  
    * **优点**：简单
    * **缺点**
      * 平均等待时间波动较大
      * 花费时间少的任务可能排在花费时间长的任务后面
      * 可能导致I/O和CPU之间的重叠处理
        * CPU密集型进程会导致I/O设备闲置时，I/O密集型进程也在等待  
  * **SPN（SJF） SRT（短进程优先（短作业优先）短剩余时间优先）调度算法**  
  &emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%9F%AD%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88.PNG" width=45% /><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%9F%AD%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88%E6%9C%80%E4%BC%98%E5%B9%B3%E5%9D%87%E7%AD%89%E5%BE%85%E6%97%B6%E9%97%B4.PNG" width=46.85% />  
&emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%9F%AD%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88%E5%AF%B9%E6%9C%AA%E6%9D%A5%E7%9A%84%E9%A2%84%E6%B5%8B.PNG" width=43.6% />&emsp;&emsp;&ensp;&ensp;&ensp;&nbsp;&nbsp;&nbsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E7%9F%AD%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C.PNG" width=40% />
  * **HRRN（最高响应比优先）**  
  &emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E6%9C%80%E9%AB%98%E5%93%8D%E5%BA%94%E4%BC%98%E5%85%88%E6%AF%94.PNG" width=43.6% />
   
* **调度算法 2**
  * **Round Robin（轮循）调度算法**  
  <div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BD%AE%E5%BE%AA.PNG" width=50% /></div>
  &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BD%AE%E5%BE%AA%E7%AD%89%E5%BE%85%E6%97%B6%E9%97%B4.PNG" width=46% /> &emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E8%BD%AE%E5%BE%AA%E6%97%B6%E9%97%B4%E7%89%87%E9%80%89%E6%8B%A9.PNG" width=43.6% />   

   * RR花销：额外的上下文切换
   * 时间量子太大
     * 等待时间过长
     * 极限情况退化成FCFS
   * 时间量子太小
     * 反应迅速，但是....
     * 吞吐量由于大量的上下文切换开销收到影响
   * 目标
     * 选择一个合适的时间量子
     * **经验规矩：维持上下文切换开销处于1%以内**
* **实时调度**
  * **定义**：正确性依赖于其时间和功能两方面的一种操作系统。
  * **性能指标**
    * 时间约束的及时性（deadlines）
    * 速度和平均性能相对不重要
  * **主要特性**
    * 时间约束的可预测性
  * **强实时系统**
    * 需要在保证的时间内完成重要的任务，必须完成
  * **弱实时系统**
    * 要求重要的进程的优先级更高，尽量完成，并非必须。
  * **硬时限**
    * 如果错过了最后期限，可能会发生灾难性或非常严重的后果
    * 必须验证：在最坏的情况下也能够满足时限
    * **保证确定性**
  * **软时限**
    * 理想情况下，时限应该被最大满足。如果有时限没有被满足，那么就相应地降低要求
    * 尽最大努力去保证
  * **RM（Rate Monotonic）速率单调调度**
    * 最佳静态优先级调度
    * 通过周期安排优先级
    * 周期越短优先级越高
    * 执行周期最短的任务
  * **EDF（Earliest Deadline First）最早期限调度**
    * 最佳的动态优先级调度
    * Deadline越早优先级越高
    * 执行Deadline最早的任务
* **多处理器调度**  
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8.PNG" width=50% /></div>  

* **优先级反转**
  * 可以发生在任何基于优先级的可抢占的调度机制中
  * 当系统内的环境强制使高优先级任务等待低优先级任务时发生  
  
  <img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%BC%98%E5%85%88%E7%BA%A7%E5%8F%8D%E8%BD%AC.PNG" width=48% /> &emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%BC%98%E5%85%88%E7%BA%A7%E7%BB%A7%E6%89%BF.PNG" width=43.6% />   

  * **优先级天花板**：“资源”的优先级和“所有可以锁定该资源的任务中优先级最高的那个任务”的优先级相同
  * 除非优先级高于系统中所有被锁定的资源的优先级上限，否则任务尝试执行临界区的时候会被阻塞
  * 持有最高优先级上限信号量锁的任务，会继承被该锁所阻塞的任务的优先级

## 九.同步
* **独立线程**
  * 不和其他线程共享资源或状态
  * **确定性**=》输入状态决定结果
  * **可重现**=》能够重现起始条件，I/O
  * 调度顺序不重要
* **合作线程**
  * 在多个线程中共享状态
  * 不确定性
  * 不可重现
* **不确定性和不可重现性意味着Bug可能是间歇性发生的**
* **进程/线程**，计算机/设备需要合作
* **优点1**：共享资源
  * 一台电脑，多个用户
  * 一个银行存款余额，多台ATM机
  * 嵌入式系统（机器人控制：手臂和手的协调）
* **优点2**：加速
  * I/O操作和计算可以重叠
  * 多处理器 —— 将程序分成多个部分并行执行
* **优点3**：模块化
  * 将大程序分解成小程序
    * 以编译为例，gec会调用cpp,ccl,cc2,as,ld
  * 使系统易于扩展
* **程序可以调用函数fork（）来创建一个新的进程**
  * 操作系统需要分配一个新的并且唯一的进程ID
  * 因此在内核中，这个系统调用会运行
    * new_pid = next_pid++;
  * 翻译成机器指令
    1. LOAD next_pid Reg1
    2. STORE Reg1 new_pid
    3. INC Reg1
    4. STORE Reg1 next_pid
* **假设两个进程并发执行**
  * 如果nexd_pid等于100，那么其中一个进程得到的ID应该是100，另一个进程的ID应该是101，next_pid应该增加到102
* **无论多个线程的指令序列怎样交替执行，程序都必须正常工作**
  * 多线程程序具有不确定性和不可重现性的特点
  * 不经过专门设计，调试难度很高
* **不确定性要求并行程序的正确性** 
  * 先思考清楚问题，把程序的行为设计清楚
  * 切忌急于着手编写代码，碰到问题再调试
* **系统缺陷：结果依赖于并发执行或者事件的顺序/时间**
  * **不确定性**
  * **不可重现性**
* **原子操作是指一次不存在任何中断或者失败的执行**
  * 该执行成功结束
  * 或者根本没有执行
  * 并且不应该发现任何部分执行的状态
* **实际上操作往往不是原子的**
  * 有些看上去是原子操作，实际上不是
  * 连X++这样的简单语句，实际上是由3条指令构成的
  * 有时候甚至连单条机器指令都不是原子的
    * Pieline,super-scalar,page fault  
&nbsp;    
* **Critical section(临界区)：是指进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域**
* **Mutual exclusion(互斥)：当一个进程处于临界区并访问共享资源时，没有其他的进程会处于临界区并且访问任何相同的共享资源**
* **Dead lock（死锁）：两个或以上的进程，在相互等待完成特定任务，而最终没法将自身任务进行下去**
* **Starvation（饥饿）：一个可执行的进程，被调度器持续忽略，以至于虽然处于可执行状态却不被执行**  
&nbsp;    
* **买面包案例**  
<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B9%B0%E9%9D%A2%E5%8C%85%E6%9B%B4%E5%A4%8D%E6%9D%82%E4%BE%BF%E7%AD%BE.PNG" width=50% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E6%9B%B4%E5%A4%8D%E6%9D%82%E4%BE%BF%E7%AD%BE%E7%BC%BA%E7%82%B9.PNG" width=42.5% />  
<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%B4%E7%95%8C%E5%8C%BA.PNG" width=50% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E6%96%B9%E6%A1%883%E7%BA%BF%E7%A8%8B%E4%BF%9D%E6%8A%A4.PNG" width=43% />   

* **临界区**
  * **互斥**：同一时间临界区中最多存在一个线程
  * **Process**：如果一个线程想要进入临界区，那么它最终会成功
  * **有限等待（不死锁）**：如果一个线程i处于入口区，那么在i的请求被接受之前，其他线程进入临界区的时间是有限制的。
  * **无忙等待（可选）**：如果一个进程在等待进入临界区，那么在它可以进入之前会被挂起
* **方法1：禁用硬件中断** 
  * **没有中断，没有上下文切换，因此没有并发**
    * 硬件将中断处理延迟到中断被启用之后
    * 大多数现代计算机体系结构都提供指令来完成
  * **进入临界区**
    * 禁用中断
  * **离开临界区**
    * 开启中断
  * **缺点**
    * **一旦中断被禁用，线程就无法被停止**
      * 整个系统都会为你停下来
      * 可能导致其他线程处于饥饿状态
    * **要是临界区可以任意长怎么办**
      * 无法限制响应中断所需的时间（可能存在硬件影响）
    * **要小心使用**  
    * **多CPU情况下无法很好实现互斥**
* **方法2：基于软件的解决办法**  
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E4%B8%B4%E7%95%8C%E5%8C%BA.PNG" width=50% /></div>  

  * **经典算法（1981）**  
  <img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%A4%E8%BF%9B%E7%A8%8B%E7%BB%8F%E5%85%B8%E4%BA%92%E6%96%A5.PNG" width=50% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%A4%E7%BA%BF%E7%A8%8B%E7%BB%8F%E5%85%B8%E4%BA%92%E6%96%A5%E8%BF%9B%E7%A8%8BPI%E7%AE%97%E6%B3%95.PNG" width=45.1% />  
  * **临界区算法（1965 & 1979）**  
  <img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/Bakery%E7%AE%97%E6%B3%95.PNG" width=52% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/%E4%B8%B4%E7%95%8C%E5%8C%BA%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93.PNG" width=45.1% />

* **方法3：更高级的抽象**  
  * **硬件提供了一些原语**
    * 像中断禁用，原子操作指令等
    * 大多数现代体系结构都这样
  * **操作系统提供更高级的编程抽象来简化并行编程**
    * 例如：锁，信号量
    * 从硬件原语中构建
  * **锁是一个抽象的数据结构**
    * 一个二进制状态（锁定/解锁），两种方法
    * Lock::Acquire() - 锁被释放前一直等待，然后得到锁
    * Lock::Release() - 释放锁，唤醒任何等待的进程
  * **使用锁来别写临界区**
    * 前面的例子变得简单起来：
      * lock_next_pid->Acquire();
      * new_pid = next_pid++;
      * lock_next_pid->Release();
  * **大多数现代体系结构都提供特殊的原子操作指令**
    * 通过特殊的内存访问电路
    * 针对单处理器和多处理器
  * **原子指令：Test-and-Set测试和置位**
    * 从内存中读取
    * 测试该值是否为1（然后返回真或假）
    * 内存值设置为1
  * **原子指令：交换**
    * 交换内存中的两个值  
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/9.8%E4%B8%A4%E6%9D%A1%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E6%8C%87%E4%BB%A4.PNG" width=50% /></div>

&emsp;&emsp;&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/9.8test-and-set%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.PNG" width=43.1% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/9.8exchange%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.PNG" width=48% />
  * **忙等**：是指一个进程的线程获得了锁，在该进程未释放锁之前，其他进程在等待获得该锁的时候都是忙等，也就是锁处于“忙状态”，此时，CPU被处于忙等的进程占用时会造成资源的浪费，所以称为忙等。为了避免忙等，可以将处于忙等的进程存入进程队列中，避免其对CPU的占用，也就避免了忙等。  
&nbsp;  
&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/9.8%E5%BF%99%E7%AD%89.PNG" width=44.6% /> &emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/9.8%E6%97%A0%E5%BF%99%E7%AD%89.PNG" width=50% />

## 十.信号量和管程
* **锁**  
<div align="center"><img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/10.1%E9%94%81.PNG" width=50% /></div>  

* **信号量（sem）**  
&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/10.2%E4%BF%A1%E5%8F%B7%E9%87%8F.PNG" width=40% />&emsp;<img src="https://github.com/84634628/ZC-Notes/blob/master/docs/pictures/10.2PV.PNG" width=50.5% />
* **信号量属性**
  * 信号量是**整数**
  * 信号量是**被保护**的变量
    * 初始化完成后，唯一改变一个信号量的值的办法是通过P()和V()
    * 操作必须是原子
  * **P（）能够阻塞**，V（）不会阻塞
  * 我们假定信号量是“公平的”
    * 没有线程被阻塞在P（）仍然堵塞如果V（）被无限频繁调用（在同一个信号量）
    * 在实践中，FIFO经常被使用
  * **两种类型信号量**
    * 二进制信号量：可以是0或1
    * 一般/计数信号量：可取任何非负值
    * 两者互相表现（给定一个可以实现另一个）
  * **信号量可以用在两个方面**
    * 互斥
    * 条件同步（调度约束  一个线程等待另一个线程的事情发生）
* **信号量的使用**
  * 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   
   
   
   
   
   
   
   
   
   
